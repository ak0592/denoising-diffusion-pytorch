{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sklearn.datasets\n",
    "import sys\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from denoising_diffusion_pytorch import Unet, GaussianDiffusion\n",
    "\n",
    "\n",
    "pio.renderers.default = \"chrome\"\n",
    "pio.templates.default = \"plotly\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "world_map = cv2.imread('/Users/kodamaakira/research-embedding/notebooks/continuous_projection/colored_world_map3.jpeg')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dog_img = cv2.imread(\"/Users/kodamaakira/denoising-diffusion-pytorch/images/dog.png\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(128, 128, 3)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_img.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 3, 128, 128])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.expand_dims(np.transpose(world_map[:128, :128], (2, 0, 1)), 0)).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "fig = px.imshow(world_map)\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def normalize_img(img):\n",
    "    result = []\n",
    "    for channel in range(img.shape[0]):\n",
    "        result.append(img[channel] / img[channel].max())\n",
    "\n",
    "    return np.stack(result, axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([817, 497, 139, 461, 478, 710,   1, 183])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Unet(\n",
    "    dim=64,\n",
    "    dim_mults=(1, 2, 4, 8)\n",
    ")\n",
    "\n",
    "diffusion = GaussianDiffusion(\n",
    "    model,\n",
    "    image_size=128,\n",
    "    timesteps=1000,  # number of steps\n",
    "    loss_type='l1'  # L1 or L2\n",
    ")\n",
    "\n",
    "training_images = torch.randn(8, 3, 128, 128)  # images are normalized from 0 to 1\n",
    "input_img = np.stack([normalize_img(np.transpose(dog_img, (2, 0, 1)))] * 8, axis=0)\n",
    "\n",
    "noise_sample, t = diffusion(torch.from_numpy(input_img).float())\n",
    "noise_sample = noise_sample.numpy()\n",
    "t"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([8, 3, 128, 128])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_sample.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "(1, 3, 128, 128)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_img(np.transpose(world_map[:128, :128], (2, 0, 1))).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(8, 1, 128, 128)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_img.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "fig = px.imshow(np.transpose(input_img[0], (1, 2, 0)))\n",
    "fig.update_layout(title=\"normalized input image\")\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def re_normalize(noises):\n",
    "    result = []\n",
    "    for noise in noises:\n",
    "        min_value = np.tile(noise.reshape(3, -1).min(axis=1).reshape(3, 1, 1), (1, 128, 128))\n",
    "        x = noise - min_value\n",
    "        result.append(x / np.tile(x.reshape(3, -1).max(axis=1).reshape(3, 1, 1), (1, 128, 128)) * 255)\n",
    "\n",
    "    return np.stack(result, axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(8, 3, 128, 128)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "renormalized_noise_sample = re_normalize(noise_sample)\n",
    "\n",
    "renormalized_noise_sample.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "target_id = 3\n",
    "fig = px.imshow(np.transpose(renormalized_noise_sample[target_id], (1, 2, 0)))\n",
    "fig.update_layout(title=f\"t = {t[target_id]}\")\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(1, 3, 128, 128)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_img.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "reshaped_input = np.squeeze(input_img).reshape(3, -1).T\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=reshaped_input[:, 0], y=reshaped_input[:, 1], z=reshaped_input[:, 2],\n",
    "    mode=\"markers\",\n",
    "    marker={\n",
    "        \"size\": 2\n",
    "    }\n",
    "))\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "target_id = 4\n",
    "fig = go.Figure()\n",
    "reshaped_noise = noise_sample.reshape(8, 3, -1)\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=reshaped_noise[target_id, 0], y=reshaped_noise[target_id, 1], z=reshaped_noise[target_id, 2],\n",
    "    mode=\"markers\",\n",
    "    marker={\n",
    "        \"size\": 2\n",
    "    }\n",
    "))\n",
    "fig.update_layout(title=f\"t = {t[target_id]}\")\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "target_id = 3\n",
    "fig = go.Figure()\n",
    "reshaped_noise = noise_sample.reshape(8, 3, -1)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=reshaped_noise[target_id, 0], y=reshaped_noise[target_id, 1],\n",
    "    mode=\"markers\",\n",
    "    marker={\n",
    "        \"size\": 4\n",
    "    }\n",
    "))\n",
    "fig.update_layout(title=f\"t = {t[target_id]}\")\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.transpose(training_images[0], (1, 2, 0))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
